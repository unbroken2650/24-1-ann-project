{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "paTQndvOsqP0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-18 23:48:09.068714: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-18 23:48:09.068747: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-18 23:48:09.068776: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-18 23:48:09.074804: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-18 23:48:09.811602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading training data: 12it [00:02,  5.09it/s]\n",
            "Loading test data: 2it [00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(112799, 785) (18799, 785)\n",
            "x_train shape: (101519, 28, 28, 1)\n",
            "x_test shape: (18799, 28, 28, 1)\n",
            "x_valid shape: (11280, 28, 28, 1)\n",
            "y_train shape: (101519,)\n",
            "y_test shape: (18799,)\n",
            "y_valid shape: (11280,)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout, ELU, BatchNormalization, PReLU, Add, Input,GlobalAveragePooling2D,ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
        "import numpy as np\n",
        "import gzip\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_file_path = '../../../../mnt/sda/suhohan/emnist/emnist-balanced-train.csv'\n",
        "test_file_path = '../../../../mnt/sda/suhohan/emnist/emnist-balanced-test.csv'\n",
        "\n",
        "chunk_size = 10000\n",
        "train_data_iter = pd.read_csv(train_file_path, chunksize=chunk_size)\n",
        "train_data = pd.concat([chunk for chunk in tqdm(train_data_iter, desc='Loading training data')])\n",
        "test_data_iter = pd.read_csv(test_file_path, chunksize=chunk_size)\n",
        "test_data = pd.concat([chunk for chunk in tqdm(test_data_iter, desc='Loading test data')])\n",
        "\n",
        "print(train_data.shape, test_data.shape)\n",
        "\n",
        "# 데이터의 차원과 크기를 정확히 파악\n",
        "num_train_samples = train_data.shape[0]\n",
        "num_test_samples = test_data.shape[0]\n",
        "\n",
        "# 데이터 준비\n",
        "x_train = train_data.iloc[:, 1:].to_numpy().reshape((num_train_samples, 28, 28, 1))\n",
        "x_test = test_data.iloc[:, 1:].to_numpy().reshape((num_test_samples, 28, 28, 1))\n",
        "y_train = train_data.iloc[:, 0].to_numpy()\n",
        "y_test = test_data.iloc[:, 0].to_numpy()  \n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"x_valid shape:\", x_valid.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "print(\"y_valid shape:\", y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "26jEHv5h7mL-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-18 23:48:14.430095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-18 23:48:14.455258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-18 23:48:14.455585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-18 23:48:14.460044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-18 23:48:14.460397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-18 23:48:14.460666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-18 23:48:15.412925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-18 23:48:15.602659: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-18 23:48:15.603028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-18 23:48:15.603256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 116 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:c2:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "    y = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = PReLU()(y)\n",
        "    y = Conv2D(filters, kernel_size, strides=1, padding='same')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "\n",
        "    if stride != 1 or x.shape[-1] != filters:\n",
        "        x = Conv2D(filters, 1, strides=stride, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "    out = Add()([x, y])\n",
        "    out = PReLU()(out)\n",
        "    return out\n",
        "\n",
        "input = Input(shape=(28, 28, 1))\n",
        "x = Conv2D(32, (3, 3), padding='same')(input)\n",
        "x = BatchNormalization()(x)\n",
        "x = PReLU()(x)\n",
        "x = Dropout(0.33)(x)\n",
        "x = AveragePooling2D(pool_size=2, strides=2, padding='valid')(x)\n",
        "\n",
        "x = residual_block(x, 64)\n",
        "x = Dropout(0.33)(x)\n",
        "x = AveragePooling2D(pool_size=2, strides=2, padding='valid')(x)\n",
        "\n",
        "x = residual_block(x, 128)\n",
        "x = Dropout(0.33)(x)\n",
        "x = AveragePooling2D(pool_size=2, strides=2, padding='valid')(x)\n",
        "\n",
        "x = residual_block(x, 256)\n",
        "x = Dropout(0.33)(x)\n",
        "x = AveragePooling2D(pool_size=2, strides=2, padding='valid')(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(512)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = PReLU()(x)\n",
        "x = Dropout(0.6)(x)\n",
        "\n",
        "output = Dense(47, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input, outputs=output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 28, 28, 32)           320       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 28, 28, 32)           128       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " p_re_lu (PReLU)             (None, 28, 28, 32)           25088     ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 28, 28, 32)           0         ['p_re_lu[0][0]']             \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 14, 14, 32)           0         ['dropout[0][0]']             \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)           18496     ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 14, 14, 64)           256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " p_re_lu_1 (PReLU)           (None, 14, 14, 64)           12544     ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 64)           2112      ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 64)           36928     ['p_re_lu_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 14, 14, 64)           256       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 14, 14, 64)           256       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 14, 14, 64)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    , 'batch_normalization_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " p_re_lu_2 (PReLU)           (None, 14, 14, 64)           12544     ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 14, 14, 64)           0         ['p_re_lu_2[0][0]']           \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (Avera  (None, 7, 7, 64)             0         ['dropout_1[0][0]']           \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 7, 7, 128)            73856     ['average_pooling2d_1[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 7, 7, 128)            512       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " p_re_lu_3 (PReLU)           (None, 7, 7, 128)            6272      ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 7, 7, 128)            8320      ['average_pooling2d_1[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 128)            147584    ['p_re_lu_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 7, 7, 128)            512       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 7, 7, 128)            512       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 7, 7, 128)            0         ['batch_normalization_6[0][0]'\n",
            "                                                                    , 'batch_normalization_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " p_re_lu_4 (PReLU)           (None, 7, 7, 128)            6272      ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 7, 7, 128)            0         ['p_re_lu_4[0][0]']           \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (Avera  (None, 3, 3, 128)            0         ['dropout_2[0][0]']           \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 3, 3, 256)            295168    ['average_pooling2d_2[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 3, 3, 256)            1024      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " p_re_lu_5 (PReLU)           (None, 3, 3, 256)            2304      ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 3, 3, 256)            33024     ['average_pooling2d_2[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 3, 3, 256)            590080    ['p_re_lu_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 3, 3, 256)            1024      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 3, 3, 256)            1024      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 3, 3, 256)            0         ['batch_normalization_9[0][0]'\n",
            "                                                                    , 'batch_normalization_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " p_re_lu_6 (PReLU)           (None, 3, 3, 256)            2304      ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 3, 3, 256)            0         ['p_re_lu_6[0][0]']           \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (Avera  (None, 1, 1, 256)            0         ['dropout_3[0][0]']           \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 256)                  0         ['average_pooling2d_3[0][0]'] \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 512)                  131584    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 512)                  2048      ['dense[0][0]']               \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " p_re_lu_7 (PReLU)           (None, 512)                  512       ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 512)                  0         ['p_re_lu_7[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 47)                   24111     ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1436975 (5.48 MB)\n",
            "Trainable params: 1433199 (5.47 MB)\n",
            "Non-trainable params: 3776 (14.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPq_U6u2tjME",
        "outputId": "49f8e13f-ed48-4db1-a998-c0f3d0829233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-18 16:57:56.410605: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
            "2024-05-18 16:57:57.924580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8800\n",
            "2024-05-18 16:57:59.694440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x766260f46f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-05-18 16:57:59.694465: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
            "2024-05-18 16:57:59.698116: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-05-18 16:57:59.776041: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "204/204 [==============================] - 15s 29ms/step - loss: 1.1978 - accuracy: 0.6502 - val_loss: 0.4929 - val_accuracy: 0.8379 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.4858 - accuracy: 0.8325 - val_loss: 0.3569 - val_accuracy: 0.8715 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.4109 - accuracy: 0.8550 - val_loss: 0.3404 - val_accuracy: 0.8813 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.3776 - accuracy: 0.8662 - val_loss: 0.3340 - val_accuracy: 0.8805 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.3498 - accuracy: 0.8736 - val_loss: 0.2984 - val_accuracy: 0.8879 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.3284 - accuracy: 0.8809 - val_loss: 0.2928 - val_accuracy: 0.8890 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "204/204 [==============================] - 5s 23ms/step - loss: 0.3235 - accuracy: 0.8818 - val_loss: 0.2946 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "204/204 [==============================] - 5s 24ms/step - loss: 0.3081 - accuracy: 0.8869 - val_loss: 0.2938 - val_accuracy: 0.8902 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.2994 - accuracy: 0.8894 - val_loss: 0.2923 - val_accuracy: 0.8914 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.2868 - accuracy: 0.8932 - val_loss: 0.2913 - val_accuracy: 0.8922 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.2803 - accuracy: 0.8944 - val_loss: 0.2764 - val_accuracy: 0.8991 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.2730 - accuracy: 0.8974 - val_loss: 0.2719 - val_accuracy: 0.8992 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.2658 - accuracy: 0.8976 - val_loss: 0.2815 - val_accuracy: 0.8962 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "204/204 [==============================] - 5s 27ms/step - loss: 0.2624 - accuracy: 0.9003 - val_loss: 0.2782 - val_accuracy: 0.8947 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.2596 - accuracy: 0.8997 - val_loss: 0.2760 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "204/204 [==============================] - 5s 24ms/step - loss: 0.2338 - accuracy: 0.9088 - val_loss: 0.2639 - val_accuracy: 0.9038 - lr: 5.0000e-04\n",
            "Epoch 17/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.2251 - accuracy: 0.9119 - val_loss: 0.2823 - val_accuracy: 0.8983 - lr: 5.0000e-04\n",
            "Epoch 18/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.2214 - accuracy: 0.9133 - val_loss: 0.2680 - val_accuracy: 0.9034 - lr: 5.0000e-04\n",
            "Epoch 19/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.2167 - accuracy: 0.9141 - val_loss: 0.2693 - val_accuracy: 0.9033 - lr: 5.0000e-04\n",
            "Epoch 20/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.2072 - accuracy: 0.9165 - val_loss: 0.2644 - val_accuracy: 0.9033 - lr: 2.5000e-04\n",
            "Epoch 21/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.2003 - accuracy: 0.9199 - val_loss: 0.2613 - val_accuracy: 0.9047 - lr: 2.5000e-04\n",
            "Epoch 22/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1951 - accuracy: 0.9208 - val_loss: 0.2665 - val_accuracy: 0.9053 - lr: 2.5000e-04\n",
            "Epoch 23/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1954 - accuracy: 0.9215 - val_loss: 0.2695 - val_accuracy: 0.9029 - lr: 2.5000e-04\n",
            "Epoch 24/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1915 - accuracy: 0.9222 - val_loss: 0.2708 - val_accuracy: 0.9041 - lr: 2.5000e-04\n",
            "Epoch 25/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1865 - accuracy: 0.9245 - val_loss: 0.2703 - val_accuracy: 0.9048 - lr: 1.2500e-04\n",
            "Epoch 26/50\n",
            "204/204 [==============================] - 5s 24ms/step - loss: 0.1817 - accuracy: 0.9245 - val_loss: 0.2700 - val_accuracy: 0.9062 - lr: 1.2500e-04\n",
            "Epoch 27/50\n",
            "204/204 [==============================] - 5s 24ms/step - loss: 0.1803 - accuracy: 0.9258 - val_loss: 0.2681 - val_accuracy: 0.9056 - lr: 1.2500e-04\n",
            "Epoch 28/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1758 - accuracy: 0.9282 - val_loss: 0.2703 - val_accuracy: 0.9049 - lr: 6.2500e-05\n",
            "Epoch 29/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1743 - accuracy: 0.9281 - val_loss: 0.2726 - val_accuracy: 0.9066 - lr: 6.2500e-05\n",
            "Epoch 30/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1735 - accuracy: 0.9277 - val_loss: 0.2732 - val_accuracy: 0.9060 - lr: 6.2500e-05\n",
            "Epoch 31/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1713 - accuracy: 0.9289 - val_loss: 0.2728 - val_accuracy: 0.9061 - lr: 3.1250e-05\n",
            "Epoch 32/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1710 - accuracy: 0.9289 - val_loss: 0.2727 - val_accuracy: 0.9062 - lr: 3.1250e-05\n",
            "Epoch 33/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1699 - accuracy: 0.9296 - val_loss: 0.2724 - val_accuracy: 0.9054 - lr: 3.1250e-05\n",
            "Epoch 34/50\n",
            "204/204 [==============================] - 5s 24ms/step - loss: 0.1693 - accuracy: 0.9295 - val_loss: 0.2727 - val_accuracy: 0.9063 - lr: 1.5625e-05\n",
            "Epoch 35/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1680 - accuracy: 0.9297 - val_loss: 0.2731 - val_accuracy: 0.9057 - lr: 1.5625e-05\n",
            "Epoch 36/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1670 - accuracy: 0.9304 - val_loss: 0.2725 - val_accuracy: 0.9063 - lr: 1.5625e-05\n",
            "Epoch 37/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1676 - accuracy: 0.9307 - val_loss: 0.2731 - val_accuracy: 0.9060 - lr: 7.8125e-06\n",
            "Epoch 38/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1671 - accuracy: 0.9301 - val_loss: 0.2729 - val_accuracy: 0.9056 - lr: 7.8125e-06\n",
            "Epoch 39/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1672 - accuracy: 0.9305 - val_loss: 0.2731 - val_accuracy: 0.9058 - lr: 7.8125e-06\n",
            "Epoch 40/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1668 - accuracy: 0.9307 - val_loss: 0.2734 - val_accuracy: 0.9052 - lr: 3.9063e-06\n",
            "Epoch 41/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1672 - accuracy: 0.9297 - val_loss: 0.2735 - val_accuracy: 0.9053 - lr: 3.9063e-06\n",
            "Epoch 42/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1673 - accuracy: 0.9305 - val_loss: 0.2735 - val_accuracy: 0.9053 - lr: 3.9063e-06\n",
            "Epoch 43/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1674 - accuracy: 0.9307 - val_loss: 0.2738 - val_accuracy: 0.9056 - lr: 1.9531e-06\n",
            "Epoch 44/50\n",
            "204/204 [==============================] - 5s 27ms/step - loss: 0.1667 - accuracy: 0.9308 - val_loss: 0.2737 - val_accuracy: 0.9054 - lr: 1.9531e-06\n",
            "Epoch 45/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1668 - accuracy: 0.9306 - val_loss: 0.2737 - val_accuracy: 0.9058 - lr: 1.9531e-06\n",
            "Epoch 46/50\n",
            "204/204 [==============================] - 5s 27ms/step - loss: 0.1679 - accuracy: 0.9299 - val_loss: 0.2739 - val_accuracy: 0.9053 - lr: 1.0000e-06\n",
            "Epoch 47/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1663 - accuracy: 0.9304 - val_loss: 0.2735 - val_accuracy: 0.9054 - lr: 1.0000e-06\n",
            "Epoch 48/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1658 - accuracy: 0.9310 - val_loss: 0.2735 - val_accuracy: 0.9055 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "204/204 [==============================] - 5s 26ms/step - loss: 0.1669 - accuracy: 0.9305 - val_loss: 0.2738 - val_accuracy: 0.9055 - lr: 1.0000e-06\n",
            "Epoch 50/50\n",
            "204/204 [==============================] - 5s 25ms/step - loss: 0.1670 - accuracy: 0.9304 - val_loss: 0.2739 - val_accuracy: 0.9056 - lr: 1.0000e-06\n",
            "588/588 [==============================] - 2s 4ms/step - loss: 0.2893 - accuracy: 0.9052\n",
            "Test accuracy: 0.9052077531814575\n"
          ]
        }
      ],
      "source": [
        "optimizer = Adam(learning_rate=0.001)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.000001)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=50, callbacks=[reduce_lr], batch_size=500)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "bgX59k6F3SsF",
        "outputId": "5f62249e-df1f-4200-d5db-2fc6f669ce92"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 - 2s - loss: 0.2893 - accuracy: 0.9052 - 2s/epoch - 4ms/step\n",
            "Test accuracy: 0.9052077531814575\n"
          ]
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
