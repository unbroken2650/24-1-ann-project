{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdO1JXydFAMo"
      },
      "outputs": [],
      "source": [
        "from keras import models, layers, optimizers, callbacks\n",
        "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
        "\n",
        "\n",
        "class ResModel:\n",
        "    def __init__(self, num_classes=62, initial_filters=32, dropout_rate=0.3, final_dropout_rate=0.6, activation='ReLU', num_residual_units=3):\n",
        "        self.num_classes = num_classes\n",
        "        self.initial_filters = initial_filters\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.final_dropout_rate = final_dropout_rate\n",
        "        self.activation = activation\n",
        "        self.num_residual_units = num_residual_units\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def residual_block(self, x, filters, kernel_size=3, stride=1):\n",
        "        y = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "        y = layers.BatchNormalization()(y)\n",
        "        y = self._get_activation()(y)\n",
        "        y = layers.Conv2D(filters, kernel_size, strides=1, padding='same')(y)\n",
        "        y = layers.BatchNormalization()(y)\n",
        "\n",
        "        if stride != 1 or x.shape[-1] != filters:\n",
        "            x = layers.Conv2D(filters, 1, strides=stride, padding='same')(x)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "\n",
        "        out = layers.Add()([x, y])\n",
        "        out = self._get_activation()(out)\n",
        "        return out\n",
        "\n",
        "    def build_model(self):\n",
        "        input = layers.Input(shape=(28, 28, 1))\n",
        "        x = layers.Conv2D(self.initial_filters, (3, 3), padding='same')(input)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = self._get_activation()(x)\n",
        "        x = layers.Dropout(self.dropout_rate)(x)\n",
        "        x = layers.AveragePooling2D(pool_size=2, strides=2, padding='same')(x)\n",
        "\n",
        "        filters = self.initial_filters * 2\n",
        "        for _ in range(self.num_residual_units):\n",
        "            x = self.residual_block(x, filters)\n",
        "            x = layers.Dropout(self.dropout_rate)(x)\n",
        "            x = layers.AveragePooling2D(pool_size=2, strides=2, padding='same')(x)\n",
        "            filters *= 2\n",
        "\n",
        "        x = layers.Flatten()(x)\n",
        "        x = layers.Dense(512)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = self._get_activation()(x)\n",
        "        x = layers.Dropout(self.final_dropout_rate)(x)\n",
        "\n",
        "        output = layers.Dense(self.num_classes, activation='softmax')(x)\n",
        "\n",
        "        model = models.Model(inputs=input, outputs=output)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _get_activation(self):\n",
        "        if self.activation == 'leaky_relu':\n",
        "            return layers.LeakyReLU()\n",
        "        elif self.activation == 'prelu':\n",
        "            return layers.PReLU(shared_axes=[1, 2])\n",
        "        else:\n",
        "            return layers.Activation(self.activation)\n",
        "\n",
        "    def compile(self, optimizer='adam', loss=None, metrics=['accuracy']):\n",
        "        if loss is None:\n",
        "            loss = SigmoidFocalCrossEntropy()\n",
        "        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    def train(self, x_train, y_train, validation_data, epochs=50, batch_size=300, callbacks=None, class_weight=None):\n",
        "        return self.model.fit(x_train, y_train, validation_data=validation_data,\n",
        "                              batch_size=batch_size, epochs=epochs, callbacks=callbacks,\n",
        "                              class_weight=class_weight)\n",
        "\n",
        "    def evaluate(self, x_test, y_test):\n",
        "        return self.model.evaluate(x_test, y_test)\n",
        "\n",
        "    def summary(self):\n",
        "        return self.model.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
