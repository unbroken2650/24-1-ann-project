{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ann-project\n",
    "\n",
    "5조\n",
    "한수호, 강구현, 김민규, 홍준기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simple_cnn import CNNModel\n",
    "from models.residual import ResModel\n",
    "from models.resnet50 import ResNetModel\n",
    "from models.lenet import LeNetModel\n",
    "from keras import callbacks, optimizers, layers, losses\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import random\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "result_path = './results'\n",
    "_time = datetime.strftime(datetime.today(), '%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 20:52:12.694189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 20:52:12.719588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 20:52:13.020200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 20:52:13.025485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 20:52:13.025771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 20:52:13.026026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 20:52:13.361362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 20:52:13.361659: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 20:52:13.361917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 20:52:13.362127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46681 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:c2:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_file_path = '../../../../mnt/sda/suhohan/emnist/emnist-byclass-train.csv'\n",
    "test_file_path = '../../../../mnt/sda/suhohan/emnist/emnist-byclass-test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "num_train_samples = train_data.shape[0]\n",
    "num_test_samples = test_data.shape[0]\n",
    "\n",
    "x_train = train_data.iloc[:, 1:].to_numpy().reshape((num_train_samples, 28, 28, 1))\n",
    "x_test = test_data.iloc[:, 1:].to_numpy().reshape((num_test_samples, 28, 28, 1))\n",
    "y_train = tf.keras.utils.to_categorical(train_data.iloc[:, 0], 62)\n",
    "y_test = tf.keras.utils.to_categorical(test_data.iloc[:, 0], 62)\n",
    "\n",
    "y_train_int = train_data.iloc[:, 0].to_numpy()\n",
    "y_test_int = test_data.iloc[:, 0].to_numpy()\n",
    "\n",
    "_, _, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "x_train, x_valid, y_train_int, y_valid_int = train_test_split(x_train, y_train_int, test_size=0.1, random_state=42)\n",
    "\n",
    "x_train_resized = tf.image.resize(x_train, [32, 32])\n",
    "x_valid_resized = tf.image.resize(x_valid, [32, 32])\n",
    "x_test_resized = tf.image.resize(x_test, [32, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(model_name):\n",
    "    current_time = int(time.time())\n",
    "    checkpoint_path = f\"./checkpoints/checkpoints_{model_name}/weights.{current_time}.hdf5\"\n",
    "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
    "                                             min_delta=0.0001, restore_best_weights=True)\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.000001)\n",
    "    checkpoint = callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "    return [early_stopping, reduce_lr, checkpoint]\n",
    "\n",
    "\n",
    "callbacks_lenet = create_callbacks('lenet')\n",
    "callbacks_resnet = create_callbacks('resnet')\n",
    "callbacks_ours_1 = create_callbacks('ours_1')\n",
    "callbacks_ours_2 = create_callbacks('ours_2')\n",
    "callbacks_final = create_callbacks('final')\n",
    "result_path = './results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results_df):\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    results_df.to_csv(os.path.join(result_path, f'result_{_time}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(histories, filename):\n",
    "    with open(os.path.join(result_path, filename), 'w') as f:\n",
    "        json.dump(histories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. baseline과 our 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "lenet_model = LeNetModel()\n",
    "resnet_model = ResNetModel()\n",
    "our_model_1 = CNNModel()\n",
    "our_model_2res = ResModel()\n",
    "\n",
    "# Compile models\n",
    "lenet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "resnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_2res.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history.append(lenet_model.train(x_train, y_train_int, validation_data=(x_valid, y_valid_int),\n",
    "               epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[callbacks_lenet]))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history.append(resnet_model.train(x_train_resized, y_train_int, validation_data=(x_valid_resized,\n",
    "               y_valid_int), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[callbacks_resnet]))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history.append(our_model_1.train(x_train, y_train_int, validation_data=(x_valid, y_valid_int),\n",
    "               epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[callbacks_ours_1]))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history.append(our_model_2res.train(x_train, y_train_int, validation_data=(x_valid, y_valid_int),\n",
    "               epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[callbacks_ours_2]))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lenet, acc_lenet = lenet_model.evaluate(x_test, y_test_int)\n",
    "loss_resnet, acc_resnet = resnet_model.evaluate(x_test_resized, y_test_int)\n",
    "loss_our1, acc_our1 = our_model_1.evaluate(x_test, y_test_int)\n",
    "loss_our2, acc_our2 = our_model_2res.evaluate(x_test, y_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\": [\"LeNet-5\", \"ResNet-50\", \"Our Model(CNN)\", \"Our Model(Residual)\"],\n",
    "    \"Loss\": [loss_lenet, loss_resnet, loss_our1, loss_our2],\n",
    "    \"Accuracy\": [acc_lenet, acc_resnet, acc_our1, acc_our2],\n",
    "    \"Training Time\": training_time\n",
    "}\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"lenet-5\", \"resnet-50\", \"our_model_cnn\", \"our_model_residual\"]\n",
    "for model_name, h in zip(models, history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_{model_name}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Model\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Model\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_{_time}.png\")\n",
    "plt.show()\n",
    "save_history(history, f'history_activation_{_time}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time.append(\"\")\n",
    "results = {\n",
    "    \"Model\": [\"LeNet-5\", \"ResNet-50\", \"Our Model\", \"Wavemix-256[6]\"],\n",
    "    \"Loss\": [loss_lenet, loss_resnet, loss_our1, loss_our2, 0],\n",
    "    \"Accuracy\": [acc_lenet, acc_resnet, acc_our1, acc_our2, 0.8842],\n",
    "    \"Training Time\": training_time\n",
    "}\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(5, 6))\n",
    "    sns.barplot(x=\"Model\", y=metric, hue=\"Model\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Model')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_list = [\n",
    "    optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "    optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True),\n",
    "    optimizers.Adagrad(learning_rate=0.001),\n",
    "    optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "    optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "results = {'Optimizer': [], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_opt(x_train, y_train, validation_data, optimizer, activation_ftn='ReLU'):\n",
    "    print(f\"Start with {type(optimizer).__name__}\")\n",
    "    final_model = ResModel(num_classes=62, initial_filters=32,\n",
    "                           dropout_rate=0.3, final_dropout_rate=0.6, activation=activation_ftn, num_residual_units=3)\n",
    "    optimizer.build(final_model.model.trainable_variables)\n",
    "\n",
    "    final_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = final_model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                             batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = final_model.evaluate(x_test, y_test_int)\n",
    "    results['Optimizer'].append(type(optimizer).__name__)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)\n",
    "\n",
    "    print(f\"End with {type(optimizer).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for optimizer in optimizers_list:\n",
    "    _train_opt(x_train, y_train_int, (x_valid, y_valid_int), optimizer, activation_ftn='ReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "save_results(results_df)\n",
    "for optimizer, h in zip(optimizers_list, history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_optimizer_{type(optimizer).__name__}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for i, h in enumerate(history):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(h.history['accuracy'], label=f'{type(optimizers_list[i]).__name__} Train')\n",
    "    plt.title('train accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(h.history['loss'], label=f'{type(optimizers_list[i]).__name__} Train')\n",
    "    plt.title('train loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(5, 6))\n",
    "    sns.barplot(x=\"Optimizer\", y=metric, hue=\"Optimizer\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Optimizer')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {\n",
    "    'relu': layers.ReLU(),\n",
    "    'leaky_relu': layers.LeakyReLU(),\n",
    "    'elu': layers.ELU(),\n",
    "    'selu': layers.Activation('selu'),\n",
    "    'sigmoid': layers.Activation('sigmoid'),\n",
    "    'tanh': layers.Activation('tanh'),\n",
    "    'softmax': layers.Activation('softmax'),\n",
    "    'softplus': layers.Activation('softplus'),\n",
    "    'softsign': layers.Activation('softsign'),\n",
    "    'swish': layers.Activation('swish'),\n",
    "    'gelu': layers.Activation('gelu')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "results = {'Activation Function': [], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = optimizers.legacy.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "activation_functions = ['relu', 'leaky_relu', 'elu', 'selu', 'sigmoid', 'tanh',\n",
    "                        'softmax', 'softplus', 'softsign', 'swish', 'gelu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_act(x_train, y_train, validation_data, optimizer, activation_ftn):\n",
    "    print(f\"Start with {activation_ftn}\")\n",
    "\n",
    "    activation_layer = activations.get(activation_ftn, layers.ReLU())\n",
    "\n",
    "    final_model = ResModel(num_classes=62, initial_filters=32, dropout_rate=0.3,\n",
    "                           final_dropout_rate=0.6, activation=activation_layer, num_residual_units=3)\n",
    "    final_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = final_model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                             batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = final_model.evaluate(x_test, y_test_int)\n",
    "    results['Activation Function'].append(activation_ftn)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)\n",
    "\n",
    "    print(f\"End with {activation_ftn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ftn in activation_functions:\n",
    "    _train_act(x_train, y_train_int, (x_valid, y_valid_int), optimizer=best_optimizer, activation_ftn=ftn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "save_results(results_df)\n",
    "for activation, h in zip(activation_functions, history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}  # Ensure values are float\n",
    "    save_history(history_dict, f'history_activation_{activation}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for i in range(len(activation_functions)):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history[i].history['accuracy'], label=f'{activation_functions[i]} Train')\n",
    "    plt.title('train accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history[i].history['loss'], label=f'{activation_functions[i]} Train')\n",
    "    plt.title('train loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_activation_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Activation Function\", y=\"Loss\", hue=\"Activation Function\",\n",
    "            data=results_df, palette=\"viridis\", legend=False)\n",
    "plt.title(f'{\"Loss\"} Comparison')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Activation Function')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_path}/{\"Loss\".lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Activation Function\", y=\"Accuracy\", hue=\"Activation Function\",\n",
    "            data=results_df, palette=\"viridis\", legend=False)\n",
    "plt.title(f'{\"Accuracy\"} Comparison')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Activation Function')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_path}/{\"Accuracy\".lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Activation Function\", y=\"Training Time\", hue=\"Activation Function\",\n",
    "            data=results_df, palette=\"viridis\", legend=False)\n",
    "plt.title(f'{\"Training Time\"} Comparison')\n",
    "plt.ylabel(\"Training Time\")\n",
    "plt.xlabel('Activation Function')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_path}/{\"Training Time\".lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. The number of Residual Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_final = create_callbacks('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = optimizers.legacy.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "best_activation = 'swish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_1res = ResModel(num_residual_units=1, activation=best_activation)\n",
    "our_model_2res = ResModel(num_residual_units=2, activation=best_activation)\n",
    "our_model_3res = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_4res = ResModel(num_residual_units=4, activation=best_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_1res.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_2res.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_3res.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_4res.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_blocks(model, x_train, y_train, validation_data):\n",
    "    model.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                       batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test_int)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_train_blocks(our_model_1res, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "_train_blocks(our_model_2res, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "_train_blocks(our_model_3res, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "_train_blocks(our_model_4res, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_our1res, acc_our1res = our_model_1res.evaluate(x_test, y_test_int)\n",
    "loss_our2res, acc_our2res = our_model_2res.evaluate(x_test, y_test_int)\n",
    "loss_our3res, acc_our3res = our_model_3res.evaluate(x_test, y_test_int)\n",
    "loss_our4res, acc_our4res = our_model_4res.evaluate(x_test, y_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\": [\"Our Model(Residual, 1 units)\", \"Our Model(Residual, 2 units)\", \"Our Model(Residual, 3 units)\", \"Our Model(Residual, 4 units)\"],\n",
    "    \"Loss\": [loss_our1res, loss_our2res, loss_our3res, loss_our4res],\n",
    "    \"Accuracy\": [acc_our1res, acc_our2res, acc_our3res, acc_our4res],\n",
    "    \"Training Time\": training_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_blocks_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, h in zip(range(1, 5), history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_block_{i}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\", \"orange\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Model\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Model\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0.8, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_blocks_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x=\"Model\", y=metric, hue=\"Model\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Model')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_blocks_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_final = create_callbacks('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer_1 = optimizers.legacy.Nadam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)\n",
    "best_optimizer_2 = optimizers.legacy.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "best_optimizer_3 = optimizers.legacy.Nadam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "best_optimizer_4 = optimizers.legacy.Nadam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999)\n",
    "best_optimizer_5 = optimizers.legacy.Nadam(learning_rate=0.000001, beta_1=0.9, beta_2=0.999)\n",
    "best_activation = 'swish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_1lr = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_2lr = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_3lr = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_4lr = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_5lr = ResModel(num_residual_units=3, activation=best_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_1lr.compile(optimizer=best_optimizer_1, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_2lr.compile(optimizer=best_optimizer_2, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_3lr.compile(optimizer=best_optimizer_3, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_4lr.compile(optimizer=best_optimizer_4, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_5lr.compile(optimizer=best_optimizer_5, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Learning Rate': ['1e-2', '1e-3', '1e-4', '1e-5', '1e-6'], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _train_lr(model, optimizer, x_train, y_train, validation_data):\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                       batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test_int)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_train_lr(our_model_1lr, best_optimizer_1, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_1')\n",
    "\n",
    "start_time = time.time()\n",
    "_train_lr(our_model_2lr, best_optimizer_2, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_2')\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "_train_lr(our_model_3lr, best_optimizer_3, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_3')\n",
    "\n",
    "start_time = time.time()\n",
    "_train_lr(our_model_4lr, best_optimizer_4, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_4')\n",
    "\n",
    "start_time = time.time()\n",
    "_train_lr(our_model_5lr, best_optimizer_5, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_lr_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, h in zip(range(1, 4), history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_lr_{i}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\", \"orange\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0.8, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_lr_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x=\"Learning Rate\", y=metric, hue=\"Learning Rate\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_lr_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. Detailed learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_final = create_callbacks('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_activation = 'swish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Learning Rate': ['1e−3', '9e−4', '8e−4', '7e−4', '6e−4',\n",
    "                             '5e−4', '4e−4', '3e−4', '2e−4', '1e−4'], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_lr(learning_rate, x_train, y_train, validation_data):\n",
    "    model = ResModel(num_residual_units=3, activation=best_activation)\n",
    "    _optimizer = optimizers.legacy.Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(optimizer=_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                       batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test_int)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(1e-3, 1e-4, 10):\n",
    "    start_time = time.time()\n",
    "    _train_lr(i, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "    end_time = time.time()\n",
    "    training_time.append(end_time-start_time)\n",
    "    callbacks_final = create_callbacks(f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_lr_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, h in zip(['1e−3', '9e−4', '8e−4', '7e−4', '6e−4',\n",
    "                 '5e−4', '4e−4', '3e−4', '2e−4', '1e−4'], history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_lr_{i}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\", \"orange\", \"cyan\", \"magenta\", \"brown\", \"pink\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0.8, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_lr_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x=\"Learning Rate\", y=metric, hue=\"Learning Rate\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_lr_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhohan/anaconda3/envs/ann/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_final = create_callbacks('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_activation = 'swish'\n",
    "best_learning_rate = 2e-4\n",
    "best_optimizer = optimizers.legacy.Nadam(learning_rate=best_learning_rate, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Loss Function': ['Cross Entropy Loss', 'Focal Loss'], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalFocalLoss(losses.Loss):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25):\n",
    "        super(CategoricalFocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        alpha = tf.constant(self.alpha, dtype=tf.float32)\n",
    "        gamma = tf.constant(self.gamma, dtype=tf.float32)\n",
    "\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        y_true = tf.clip_by_value(y_true, epsilon, 1.0 - epsilon)\n",
    "\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * y_true * tf.pow((1 - y_pred), gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        loss = tf.reduce_sum(loss, axis=1)\n",
    "        return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_loss = CategoricalFocalLoss(gamma=2.0, alpha=0.25)\n",
    "\n",
    "model_default = ResModel(num_residual_units=3, activation=best_activation)\n",
    "model_focal = ResModel(num_residual_units=3, activation=best_activation)\n",
    "model_default.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_focal.compile(optimizer=best_optimizer, loss=focal_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_losses(model, x_train, y_train, validation_data):\n",
    "    start_time = time.time()\n",
    "    hist = model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                       batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test_int)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:35:30.533528: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_2/dropout_10/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256/1257 [============================>.] - ETA: 0s - loss: 1.3941 - accuracy: 0.6350\n",
      "Epoch 1: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 35s 26ms/step - loss: 1.3940 - accuracy: 0.6350 - val_loss: 0.6888 - val_accuracy: 0.7845 - lr: 1.2500e-05\n",
      "Epoch 2/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.8094 - accuracy: 0.7578\n",
      "Epoch 2: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.8094 - accuracy: 0.7578 - val_loss: 0.5366 - val_accuracy: 0.8224 - lr: 1.2500e-05\n",
      "Epoch 3/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.7891\n",
      "Epoch 3: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 34s 27ms/step - loss: 0.6702 - accuracy: 0.7891 - val_loss: 0.4791 - val_accuracy: 0.8366 - lr: 1.2500e-05\n",
      "Epoch 4/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.5993 - accuracy: 0.8054\n",
      "Epoch 4: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.5993 - accuracy: 0.8054 - val_loss: 0.4476 - val_accuracy: 0.8435 - lr: 1.2500e-05\n",
      "Epoch 5/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.5536 - accuracy: 0.8167\n",
      "Epoch 5: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.5536 - accuracy: 0.8167 - val_loss: 0.4294 - val_accuracy: 0.8486 - lr: 1.2500e-05\n",
      "Epoch 6/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.8239\n",
      "Epoch 6: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.5228 - accuracy: 0.8239 - val_loss: 0.4140 - val_accuracy: 0.8525 - lr: 1.2500e-05\n",
      "Epoch 7/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.8296\n",
      "Epoch 7: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.5000 - accuracy: 0.8296 - val_loss: 0.4041 - val_accuracy: 0.8548 - lr: 1.2500e-05\n",
      "Epoch 8/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.8341\n",
      "Epoch 8: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.4834 - accuracy: 0.8341 - val_loss: 0.3969 - val_accuracy: 0.8576 - lr: 1.2500e-05\n",
      "Epoch 9/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.4681 - accuracy: 0.8378\n",
      "Epoch 9: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.4681 - accuracy: 0.8378 - val_loss: 0.3905 - val_accuracy: 0.8597 - lr: 1.2500e-05\n",
      "Epoch 10/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.4562 - accuracy: 0.8408\n",
      "Epoch 10: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.4561 - accuracy: 0.8409 - val_loss: 0.3863 - val_accuracy: 0.8603 - lr: 1.2500e-05\n",
      "Epoch 11/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8435\n",
      "Epoch 11: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.4471 - accuracy: 0.8435 - val_loss: 0.3780 - val_accuracy: 0.8625 - lr: 1.2500e-05\n",
      "Epoch 12/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.8457\n",
      "Epoch 12: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.4377 - accuracy: 0.8457 - val_loss: 0.3754 - val_accuracy: 0.8636 - lr: 1.2500e-05\n",
      "Epoch 13/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.4314 - accuracy: 0.8473\n",
      "Epoch 13: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.4314 - accuracy: 0.8474 - val_loss: 0.3727 - val_accuracy: 0.8638 - lr: 1.2500e-05\n",
      "Epoch 14/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.4249 - accuracy: 0.8491\n",
      "Epoch 14: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.4249 - accuracy: 0.8491 - val_loss: 0.3718 - val_accuracy: 0.8635 - lr: 1.2500e-05\n",
      "Epoch 15/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.8508\n",
      "Epoch 15: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.4183 - accuracy: 0.8508 - val_loss: 0.3667 - val_accuracy: 0.8652 - lr: 1.2500e-05\n",
      "Epoch 16/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.4138 - accuracy: 0.8518\n",
      "Epoch 16: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.4138 - accuracy: 0.8518 - val_loss: 0.3633 - val_accuracy: 0.8659 - lr: 1.2500e-05\n",
      "Epoch 17/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.4082 - accuracy: 0.8537\n",
      "Epoch 17: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.4082 - accuracy: 0.8537 - val_loss: 0.3612 - val_accuracy: 0.8667 - lr: 1.2500e-05\n",
      "Epoch 18/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.4047 - accuracy: 0.8547\n",
      "Epoch 18: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.4047 - accuracy: 0.8547 - val_loss: 0.3604 - val_accuracy: 0.8671 - lr: 1.2500e-05\n",
      "Epoch 19/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.4007 - accuracy: 0.8555\n",
      "Epoch 19: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.4007 - accuracy: 0.8555 - val_loss: 0.3585 - val_accuracy: 0.8682 - lr: 1.2500e-05\n",
      "Epoch 20/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.8566\n",
      "Epoch 20: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.3974 - accuracy: 0.8566 - val_loss: 0.3570 - val_accuracy: 0.8678 - lr: 1.2500e-05\n",
      "Epoch 21/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3939 - accuracy: 0.8577\n",
      "Epoch 21: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.3939 - accuracy: 0.8577 - val_loss: 0.3547 - val_accuracy: 0.8687 - lr: 1.2500e-05\n",
      "Epoch 22/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8587\n",
      "Epoch 22: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3904 - accuracy: 0.8587 - val_loss: 0.3536 - val_accuracy: 0.8689 - lr: 1.2500e-05\n",
      "Epoch 23/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.8592\n",
      "Epoch 23: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3879 - accuracy: 0.8592 - val_loss: 0.3530 - val_accuracy: 0.8691 - lr: 1.2500e-05\n",
      "Epoch 24/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8598\n",
      "Epoch 24: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3845 - accuracy: 0.8598 - val_loss: 0.3509 - val_accuracy: 0.8695 - lr: 1.2500e-05\n",
      "Epoch 25/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8603\n",
      "Epoch 25: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3829 - accuracy: 0.8603 - val_loss: 0.3509 - val_accuracy: 0.8697 - lr: 1.2500e-05\n",
      "Epoch 26/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8612\n",
      "Epoch 26: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3796 - accuracy: 0.8612 - val_loss: 0.3474 - val_accuracy: 0.8708 - lr: 1.2500e-05\n",
      "Epoch 27/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.8615\n",
      "Epoch 27: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 25ms/step - loss: 0.3783 - accuracy: 0.8615 - val_loss: 0.3464 - val_accuracy: 0.8707 - lr: 1.2500e-05\n",
      "Epoch 28/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3761 - accuracy: 0.8621\n",
      "Epoch 28: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 31s 25ms/step - loss: 0.3761 - accuracy: 0.8621 - val_loss: 0.3457 - val_accuracy: 0.8709 - lr: 1.2500e-05\n",
      "Epoch 29/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.8628\n",
      "Epoch 29: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3739 - accuracy: 0.8628 - val_loss: 0.3440 - val_accuracy: 0.8713 - lr: 1.2500e-05\n",
      "Epoch 30/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3722 - accuracy: 0.8636\n",
      "Epoch 30: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3722 - accuracy: 0.8636 - val_loss: 0.3447 - val_accuracy: 0.8714 - lr: 1.2500e-05\n",
      "Epoch 31/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3702 - accuracy: 0.8641\n",
      "Epoch 31: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3702 - accuracy: 0.8641 - val_loss: 0.3430 - val_accuracy: 0.8719 - lr: 1.2500e-05\n",
      "Epoch 32/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3684 - accuracy: 0.8644\n",
      "Epoch 32: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3684 - accuracy: 0.8644 - val_loss: 0.3430 - val_accuracy: 0.8716 - lr: 1.2500e-05\n",
      "Epoch 33/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.8649\n",
      "Epoch 33: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.3667 - accuracy: 0.8649 - val_loss: 0.3410 - val_accuracy: 0.8729 - lr: 1.2500e-05\n",
      "Epoch 34/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.8655\n",
      "Epoch 34: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3652 - accuracy: 0.8655 - val_loss: 0.3396 - val_accuracy: 0.8729 - lr: 1.2500e-05\n",
      "Epoch 35/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3639 - accuracy: 0.8652\n",
      "Epoch 35: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3639 - accuracy: 0.8652 - val_loss: 0.3403 - val_accuracy: 0.8729 - lr: 1.2500e-05\n",
      "Epoch 36/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3621 - accuracy: 0.8662\n",
      "Epoch 36: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3621 - accuracy: 0.8662 - val_loss: 0.3388 - val_accuracy: 0.8733 - lr: 1.2500e-05\n",
      "Epoch 37/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3604 - accuracy: 0.8665\n",
      "Epoch 37: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 27ms/step - loss: 0.3604 - accuracy: 0.8665 - val_loss: 0.3381 - val_accuracy: 0.8735 - lr: 1.2500e-05\n",
      "Epoch 38/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8668\n",
      "Epoch 38: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 25ms/step - loss: 0.3594 - accuracy: 0.8668 - val_loss: 0.3381 - val_accuracy: 0.8736 - lr: 1.2500e-05\n",
      "Epoch 39/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3579 - accuracy: 0.8674\n",
      "Epoch 39: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3579 - accuracy: 0.8674 - val_loss: 0.3363 - val_accuracy: 0.8742 - lr: 1.2500e-05\n",
      "Epoch 40/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3573 - accuracy: 0.8675\n",
      "Epoch 40: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3572 - accuracy: 0.8675 - val_loss: 0.3375 - val_accuracy: 0.8737 - lr: 1.2500e-05\n",
      "Epoch 41/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3563 - accuracy: 0.8680\n",
      "Epoch 41: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 27ms/step - loss: 0.3564 - accuracy: 0.8680 - val_loss: 0.3350 - val_accuracy: 0.8741 - lr: 1.2500e-05\n",
      "Epoch 42/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3549 - accuracy: 0.8684\n",
      "Epoch 42: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3549 - accuracy: 0.8684 - val_loss: 0.3352 - val_accuracy: 0.8738 - lr: 1.2500e-05\n",
      "Epoch 43/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.8690\n",
      "Epoch 43: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3533 - accuracy: 0.8690 - val_loss: 0.3353 - val_accuracy: 0.8742 - lr: 1.2500e-05\n",
      "Epoch 44/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8686\n",
      "Epoch 44: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3532 - accuracy: 0.8686 - val_loss: 0.3346 - val_accuracy: 0.8733 - lr: 1.2500e-05\n",
      "Epoch 45/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8691\n",
      "Epoch 45: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3514 - accuracy: 0.8691 - val_loss: 0.3324 - val_accuracy: 0.8745 - lr: 1.2500e-05\n",
      "Epoch 46/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3504 - accuracy: 0.8697\n",
      "Epoch 46: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 0.3504 - accuracy: 0.8697 - val_loss: 0.3335 - val_accuracy: 0.8745 - lr: 1.2500e-05\n",
      "Epoch 47/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.8697\n",
      "Epoch 47: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.3494 - accuracy: 0.8697 - val_loss: 0.3322 - val_accuracy: 0.8748 - lr: 1.2500e-05\n",
      "Epoch 48/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8700\n",
      "Epoch 48: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 0.3488 - accuracy: 0.8700 - val_loss: 0.3313 - val_accuracy: 0.8755 - lr: 1.2500e-05\n",
      "Epoch 49/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.3478 - accuracy: 0.8699\n",
      "Epoch 49: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 25ms/step - loss: 0.3478 - accuracy: 0.8699 - val_loss: 0.3328 - val_accuracy: 0.8748 - lr: 1.2500e-05\n",
      "Epoch 50/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.8704\n",
      "Epoch 50: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 25ms/step - loss: 0.3468 - accuracy: 0.8704 - val_loss: 0.3318 - val_accuracy: 0.8742 - lr: 1.2500e-05\n",
      "3636/3636 [==============================] - 9s 2ms/step - loss: 0.3263 - accuracy: 0.8761\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 22:03:04.384824: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_3/dropout_15/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1255/1257 [============================>.] - ETA: 0s - loss: 60.8555 - accuracy: 0.0164\n",
      "Epoch 1: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 35s 25ms/step - loss: 60.8542 - accuracy: 0.0164 - val_loss: 58.9657 - val_accuracy: 0.0122 - lr: 1.2500e-05\n",
      "Epoch 2/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 59.6523 - accuracy: 0.0165\n",
      "Epoch 2: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 25ms/step - loss: 59.6524 - accuracy: 0.0165 - val_loss: 58.8974 - val_accuracy: 0.0188 - lr: 1.2500e-05\n",
      "Epoch 3/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 58.9662 - accuracy: 0.0163\n",
      "Epoch 3: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 58.9661 - accuracy: 0.0163 - val_loss: 58.8858 - val_accuracy: 0.0199 - lr: 1.2500e-05\n",
      "Epoch 4/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 58.9054 - accuracy: 0.0163\n",
      "Epoch 4: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 58.9051 - accuracy: 0.0163 - val_loss: 58.8848 - val_accuracy: 0.0191 - lr: 1.2500e-05\n",
      "Epoch 5/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 58.8813 - accuracy: 0.0167\n",
      "Epoch 5: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 58.8813 - accuracy: 0.0167 - val_loss: 58.8844 - val_accuracy: 0.0184 - lr: 1.2500e-05\n",
      "Epoch 6/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 58.8702 - accuracy: 0.0164\n",
      "Epoch 6: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 58.8700 - accuracy: 0.0164 - val_loss: 58.8842 - val_accuracy: 0.0193 - lr: 1.2500e-05\n",
      "Epoch 7/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 58.8648 - accuracy: 0.0165\n",
      "Epoch 7: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 58.8642 - accuracy: 0.0165 - val_loss: 58.8841 - val_accuracy: 0.0196 - lr: 1.2500e-05\n",
      "Epoch 8/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 58.8616 - accuracy: 0.0161\n",
      "Epoch 8: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 58.8617 - accuracy: 0.0161 - val_loss: 58.8841 - val_accuracy: 0.0177 - lr: 1.2500e-05\n",
      "Epoch 9/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 58.8575 - accuracy: 0.0164\n",
      "Epoch 9: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 58.8575 - accuracy: 0.0164 - val_loss: 58.8840 - val_accuracy: 0.0187 - lr: 1.2500e-05\n",
      "Epoch 10/50\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 58.8568 - accuracy: 0.0161\n",
      "Epoch 10: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 58.8568 - accuracy: 0.0161 - val_loss: 58.8840 - val_accuracy: 0.0141 - lr: 1.2500e-05\n",
      "Epoch 11/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 58.8557 - accuracy: 0.0162\n",
      "Epoch 11: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 32s 26ms/step - loss: 58.8556 - accuracy: 0.0162 - val_loss: 58.8840 - val_accuracy: 0.0168 - lr: 1.2500e-05\n",
      "Epoch 12/50\n",
      "1255/1257 [============================>.] - ETA: 0s - loss: 58.8554 - accuracy: 0.0160\n",
      "Epoch 12: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 58.8553 - accuracy: 0.0160 - val_loss: 58.8840 - val_accuracy: 0.0175 - lr: 6.2500e-06\n",
      "Epoch 13/50\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 58.8548 - accuracy: 0.0162\n",
      "Epoch 13: val_loss did not improve from -625411456.00000\n",
      "1257/1257 [==============================] - 33s 26ms/step - loss: 58.8549 - accuracy: 0.0162 - val_loss: 58.8840 - val_accuracy: 0.0198 - lr: 6.2500e-06\n",
      "3636/3636 [==============================] - 12s 3ms/step - loss: 58.8471 - accuracy: 0.0177\n"
     ]
    }
   ],
   "source": [
    "_train_losses(model_default, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "_train_losses(model_focal, x_train, y_train_int, (x_valid, y_valid_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m results_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/result_losses_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/ann/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_losses_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, h in enumerate(history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_losses_{i}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\", \"orange\", \"cyan\", \"magenta\", \"brown\", \"pink\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Loss Function\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Loss Function\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0.8, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_losses_{_time}.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
