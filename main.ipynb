{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ann-project\n",
    "\n",
    "5조\n",
    "한수호, 강구현, 김민규, 홍준기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 15:39:11.518307: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-01 15:39:11.518356: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-01 15:39:11.518395: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-01 15:39:11.525744: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-01 15:39:12.317609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from models.simple_cnn import CNNModel\n",
    "from models.residual import ResModel\n",
    "from models.resnet50 import ResNetModel\n",
    "from models.lenet import LeNetModel\n",
    "from keras import callbacks, optimizers, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "result_path = './results'\n",
    "_time = datetime.strftime(datetime.today(), '%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 15:39:41.300009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 15:39:41.334256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 15:39:41.334626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 15:39:41.339043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 15:39:41.339320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 15:39:41.339573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 15:39:41.981006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 15:39:41.981333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 15:39:41.981599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-01 15:39:41.981820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46681 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:c2:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_file_path = '../../../../mnt/sda/suhohan/emnist/emnist-byclass-train.csv'\n",
    "test_file_path = '../../../../mnt/sda/suhohan/emnist/emnist-byclass-test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "num_train_samples = train_data.shape[0]\n",
    "num_test_samples = test_data.shape[0]\n",
    "\n",
    "x_train = train_data.iloc[:, 1:].to_numpy().reshape((num_train_samples, 28, 28, 1))\n",
    "x_test = test_data.iloc[:, 1:].to_numpy().reshape((num_test_samples, 28, 28, 1))\n",
    "y_train = tf.keras.utils.to_categorical(train_data.iloc[:, 0], 62)\n",
    "y_test = tf.keras.utils.to_categorical(test_data.iloc[:, 0], 62)\n",
    "\n",
    "y_train_int = train_data.iloc[:, 0].to_numpy()\n",
    "y_test_int = test_data.iloc[:, 0].to_numpy()\n",
    "\n",
    "_, _, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "x_train, x_valid, y_train_int, y_valid_int = train_test_split(x_train, y_train_int, test_size=0.1, random_state=42)\n",
    "\n",
    "x_train_resized = tf.image.resize(x_train, [32, 32])\n",
    "x_valid_resized = tf.image.resize(x_valid, [32, 32])\n",
    "x_test_resized = tf.image.resize(x_test, [32, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(model_name):\n",
    "    current_time = int(time.time())\n",
    "    checkpoint_path = f\"./checkpoints/checkpoints_{model_name}/weights.{current_time}.hdf5\"\n",
    "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
    "                                             min_delta=0.0001, restore_best_weights=True)\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.000001)\n",
    "    checkpoint = callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "    return [early_stopping, reduce_lr, checkpoint]\n",
    "\n",
    "\n",
    "callbacks_lenet = create_callbacks('lenet')\n",
    "callbacks_resnet = create_callbacks('resnet')\n",
    "callbacks_ours_1 = create_callbacks('ours_1')\n",
    "callbacks_ours_2 = create_callbacks('ours_2')\n",
    "callbacks_final = create_callbacks('final')\n",
    "result_path = './results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results_df):\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    results_df.to_csv(os.path.join(result_path, f'result_{_time}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(histories, filename):\n",
    "    with open(os.path.join(result_path, filename), 'w') as f:\n",
    "        json.dump(histories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. baseline과 our 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "lenet_model = LeNetModel()\n",
    "resnet_model = ResNetModel()\n",
    "our_model_1 = CNNModel()\n",
    "our_model_2res = ResModel()\n",
    "\n",
    "# Compile models\n",
    "lenet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "resnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_2res.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history.append(lenet_model.train(x_train, y_train_int, validation_data=(x_valid, y_valid_int),\n",
    "               epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[callbacks_lenet]))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history.append(resnet_model.train(x_train_resized, y_train_int, validation_data=(x_valid_resized,\n",
    "               y_valid_int), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[callbacks_resnet]))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history.append(our_model_1.train(x_train, y_train_int, validation_data=(x_valid, y_valid_int),\n",
    "               epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[callbacks_ours_1]))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history.append(our_model_2res.train(x_train, y_train_int, validation_data=(x_valid, y_valid_int),\n",
    "               epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[callbacks_ours_2]))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lenet, acc_lenet = lenet_model.evaluate(x_test, y_test_int)\n",
    "loss_resnet, acc_resnet = resnet_model.evaluate(x_test_resized, y_test_int)\n",
    "loss_our1, acc_our1 = our_model_1.evaluate(x_test, y_test_int)\n",
    "loss_our2, acc_our2 = our_model_2res.evaluate(x_test, y_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\": [\"LeNet-5\", \"ResNet-50\", \"Our Model(CNN)\", \"Our Model(Residual)\"],\n",
    "    \"Loss\": [loss_lenet, loss_resnet, loss_our1, loss_our2],\n",
    "    \"Accuracy\": [acc_lenet, acc_resnet, acc_our1, acc_our2],\n",
    "    \"Training Time\": training_time\n",
    "}\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"lenet-5\", \"resnet-50\", \"our_model_cnn\", \"our_model_residual\"]\n",
    "for model_name, h in zip(models, history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_{model_name}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Model\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Model\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_{_time}.png\")\n",
    "plt.show()\n",
    "save_history(history, f'history_activation_{_time}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time.append(\"\")\n",
    "results = {\n",
    "    \"Model\": [\"LeNet-5\", \"ResNet-50\", \"Our Model\", \"Wavemix-256[6]\"],\n",
    "    \"Loss\": [loss_lenet, loss_resnet, loss_our1, loss_our2, 0],\n",
    "    \"Accuracy\": [acc_lenet, acc_resnet, acc_our1, acc_our2, 0.8842],\n",
    "    \"Training Time\": training_time\n",
    "}\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(5, 6))\n",
    "    sns.barplot(x=\"Model\", y=metric, hue=\"Model\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Model')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_list = [\n",
    "    optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "    optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True),\n",
    "    optimizers.Adagrad(learning_rate=0.001),\n",
    "    optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "    optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "results = {'Optimizer': [], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_opt(x_train, y_train, validation_data, optimizer, activation_ftn='ReLU'):\n",
    "    print(f\"Start with {type(optimizer).__name__}\")\n",
    "    final_model = ResModel(num_classes=62, initial_filters=32,\n",
    "                           dropout_rate=0.3, final_dropout_rate=0.6, activation=activation_ftn, num_residual_units=3)\n",
    "    optimizer.build(final_model.model.trainable_variables)\n",
    "\n",
    "    final_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = final_model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                             batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = final_model.evaluate(x_test, y_test_int)\n",
    "    results['Optimizer'].append(type(optimizer).__name__)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)\n",
    "\n",
    "    print(f\"End with {type(optimizer).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for optimizer in optimizers_list:\n",
    "    _train_opt(x_train, y_train_int, (x_valid, y_valid_int), optimizer, activation_ftn='ReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "save_results(results_df)\n",
    "for optimizer, h in zip(optimizers_list, history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_optimizer_{type(optimizer).__name__}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for i, h in enumerate(history):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(h.history['accuracy'], label=f'{type(optimizers_list[i]).__name__} Train')\n",
    "    plt.title('train accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(h.history['loss'], label=f'{type(optimizers_list[i]).__name__} Train')\n",
    "    plt.title('train loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(5, 6))\n",
    "    sns.barplot(x=\"Optimizer\", y=metric, hue=\"Optimizer\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Optimizer')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {\n",
    "    'relu': layers.ReLU(),\n",
    "    'leaky_relu': layers.LeakyReLU(),\n",
    "    'elu': layers.ELU(),\n",
    "    'selu': layers.Activation('selu'),\n",
    "    'sigmoid': layers.Activation('sigmoid'),\n",
    "    'tanh': layers.Activation('tanh'),\n",
    "    'softmax': layers.Activation('softmax'),\n",
    "    'softplus': layers.Activation('softplus'),\n",
    "    'softsign': layers.Activation('softsign'),\n",
    "    'swish': layers.Activation('swish'),\n",
    "    'gelu': layers.Activation('gelu')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "results = {'Activation Function': [], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = optimizers.legacy.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "activation_functions = ['relu', 'leaky_relu', 'elu', 'selu', 'sigmoid', 'tanh',\n",
    "                        'softmax', 'softplus', 'softsign', 'swish', 'gelu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_act(x_train, y_train, validation_data, optimizer, activation_ftn):\n",
    "    print(f\"Start with {activation_ftn}\")\n",
    "\n",
    "    activation_layer = activations.get(activation_ftn, layers.ReLU())\n",
    "\n",
    "    final_model = ResModel(num_classes=62, initial_filters=32, dropout_rate=0.3,\n",
    "                           final_dropout_rate=0.6, activation=activation_layer, num_residual_units=3)\n",
    "    final_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = final_model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                             batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = final_model.evaluate(x_test, y_test_int)\n",
    "    results['Activation Function'].append(activation_ftn)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)\n",
    "\n",
    "    print(f\"End with {activation_ftn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ftn in activation_functions:\n",
    "    _train_act(x_train, y_train_int, (x_valid, y_valid_int), optimizer=best_optimizer, activation_ftn=ftn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "save_results(results_df)\n",
    "for activation, h in zip(activation_functions, history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}  # Ensure values are float\n",
    "    save_history(history_dict, f'history_activation_{activation}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for i in range(len(activation_functions)):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history[i].history['accuracy'], label=f'{activation_functions[i]} Train')\n",
    "    plt.title('train accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history[i].history['loss'], label=f'{activation_functions[i]} Train')\n",
    "    plt.title('train loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_activation_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Activation Function\", y=\"Loss\", hue=\"Activation Function\",\n",
    "            data=results_df, palette=\"viridis\", legend=False)\n",
    "plt.title(f'{\"Loss\"} Comparison')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Activation Function')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_path}/{\"Loss\".lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Activation Function\", y=\"Accuracy\", hue=\"Activation Function\",\n",
    "            data=results_df, palette=\"viridis\", legend=False)\n",
    "plt.title(f'{\"Accuracy\"} Comparison')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Activation Function')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_path}/{\"Accuracy\".lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Activation Function\", y=\"Training Time\", hue=\"Activation Function\",\n",
    "            data=results_df, palette=\"viridis\", legend=False)\n",
    "plt.title(f'{\"Training Time\"} Comparison')\n",
    "plt.ylabel(\"Training Time\")\n",
    "plt.xlabel('Activation Function')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_path}/{\"Training Time\".lower().replace(\" \", \"_\")}_comparison_{_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. The number of Residual Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_final = create_callbacks('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = optimizers.legacy.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "best_activation = layers.Activation('swish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_1res = ResModel(num_residual_units=1, activation=best_activation)\n",
    "our_model_2res = ResModel(num_residual_units=2, activation=best_activation)\n",
    "our_model_3res = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_4res = ResModel(num_residual_units=4, activation=best_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_1res.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_2res.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_3res.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_4res.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_blocks(model, x_train, y_train, validation_data):\n",
    "    model.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                       batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test_int)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_train_blocks(our_model_1res, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "_train_blocks(our_model_2res, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "_train_blocks(our_model_3res, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "_train_blocks(our_model_4res, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_our1res, acc_our1res = our_model_1res.evaluate(x_test, y_test_int)\n",
    "loss_our2res, acc_our2res = our_model_2res.evaluate(x_test, y_test_int)\n",
    "loss_our3res, acc_our3res = our_model_3res.evaluate(x_test, y_test_int)\n",
    "loss_our4res, acc_our4res = our_model_4res.evaluate(x_test, y_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\": [\"Our Model(Residual, 1 units)\", \"Our Model(Residual, 2 units)\", \"Our Model(Residual, 3 units)\", \"Our Model(Residual, 4 units)\"],\n",
    "    \"Loss\": [loss_our1res, loss_our2res, loss_our3res, loss_our4res],\n",
    "    \"Accuracy\": [acc_our1res, acc_our2res, acc_our3res, acc_our4res],\n",
    "    \"Training Time\": training_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_blocks_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, h in zip(range(1, 5), history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_block_{i}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\", \"orange\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Model\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Model\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0.8, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_blocks_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x=\"Model\", y=metric, hue=\"Model\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Model')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_blocks_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_final = create_callbacks('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer_1 = optimizers.legacy.Nadam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)\n",
    "best_optimizer_2 = optimizers.legacy.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "best_optimizer_3 = optimizers.legacy.Nadam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "best_optimizer_4 = optimizers.legacy.Nadam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999)\n",
    "best_optimizer_5 = optimizers.legacy.Nadam(learning_rate=0.000001, beta_1=0.9, beta_2=0.999)\n",
    "best_activation = layers.Activation('swish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_1lr = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_2lr = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_3lr = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_4lr = ResModel(num_residual_units=3, activation=best_activation)\n",
    "our_model_5lr = ResModel(num_residual_units=3, activation=best_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_1lr.compile(optimizer=best_optimizer_1, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_2lr.compile(optimizer=best_optimizer_2, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_3lr.compile(optimizer=best_optimizer_3, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_4lr.compile(optimizer=best_optimizer_4, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "our_model_5lr.compile(optimizer=best_optimizer_5, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Learning Rate': ['1e-2', '1e-3', '1e-4', '1e-5', '1e-6'], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _train_lr(model, optimizer, x_train, y_train, validation_data):\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                       batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test_int)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "_train_lr(our_model_1lr, best_optimizer_1, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_1')\n",
    "\n",
    "start_time = time.time()\n",
    "_train_lr(our_model_2lr, best_optimizer_2, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_2')\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "_train_lr(our_model_3lr, best_optimizer_3, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_3')\n",
    "\n",
    "start_time = time.time()\n",
    "_train_lr(our_model_4lr, best_optimizer_4, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_4')\n",
    "\n",
    "start_time = time.time()\n",
    "_train_lr(our_model_5lr, best_optimizer_5, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "end_time = time.time()\n",
    "training_time.append(end_time-start_time)\n",
    "callbacks_final = create_callbacks('lr_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_lr_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, h in zip(range(1, 4), history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_lr_{i}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\", \"orange\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0.8, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_lr_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x=\"Learning Rate\", y=metric, hue=\"Learning Rate\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_lr_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. Detailed learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_final = create_callbacks('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_activation = layers.Activation('swish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Learning Rate': ['1e−3', '9e−4', '8e−4', '7e−4', '6e−4',\n",
    "                             '5e−4', '4e−4', '3e−4', '2e−4', '1e−4'], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_lr(learning_rate, x_train, y_train, validation_data):\n",
    "    model = ResModel(num_residual_units=3, activation=best_activation)\n",
    "    _optimizer = optimizers.legacy.Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(optimizer=_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    hist = model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                       batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test_int)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(1e-3, 1e-4, 10):\n",
    "    start_time = time.time()\n",
    "    _train_lr(i, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "    end_time = time.time()\n",
    "    training_time.append(end_time-start_time)\n",
    "    callbacks_final = create_callbacks(f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_lr_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, h in zip(['1e−3', '9e−4', '8e−4', '7e−4', '6e−4',\n",
    "                 '5e−4', '4e−4', '3e−4', '2e−4', '1e−4'], history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_lr_{i}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\", \"orange\", \"cyan\", \"magenta\", \"brown\", \"pink\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0.8, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_lr_{_time}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Loss\", \"Accuracy\", \"Training Time\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x=\"Learning Rate\", y=metric, hue=\"Learning Rate\", data=results_df, palette=\"viridis\", legend=False)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_path}/{metric.lower().replace(\" \", \"_\")}_comparison_lr_{_time}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhohan/anaconda3/envs/ann/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_final = create_callbacks('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_activation = layers.Activation('swish')\n",
    "best_learning_rate = 2e-4\n",
    "best_optimizer = optimizers.legacy.Nadam(learning_rate=best_learning_rate, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Loss Function': ['Cross Entropy Loss', 'Focal Loss'], 'Loss': [], 'Accuracy': [], 'Training Time': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default = ResModel(num_residual_units=3, activation=best_activation)\n",
    "model_focal = ResModel(num_residual_units=3, activation=best_activation)\n",
    "model_default.compile(optimizer=best_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_focal.compile(optimizer=best_optimizer, loss=SigmoidFocalCrossEntropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_losses(model, x_train, y_train, validation_data):\n",
    "    start_time = time.time()\n",
    "    hist = model.train(x_train, y_train, validation_data=validation_data, epochs=EPOCHS,\n",
    "                       batch_size=BATCH_SIZE, callbacks=[callbacks_final])\n",
    "    end_time = time.time()\n",
    "\n",
    "    history.append(hist)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test_int)\n",
    "    results['Loss'].append(loss)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Training Time'].append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 15:44:00.993731: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-06-01 15:44:02.227390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1257/1257 [==============================] - ETA: 0s - loss: 0.7201 - accuracy: 0.7801\n",
      "Epoch 1: val_loss improved from inf to 0.39714, saving model to ./checkpoints/checkpoints_loss/weights.1717224224.hdf5\n",
      "1257/1257 [==============================] - 39s 26ms/step - loss: 0.7201 - accuracy: 0.7801 - val_loss: 0.3971 - val_accuracy: 0.8572 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhohan/anaconda3/envs/ann/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 10s 3ms/step - loss: 0.3895 - accuracy: 0.8591\n",
      "1257/1257 [==============================] - ETA: 0s - loss: -625708032.0000 - accuracy: 0.0078\n",
      "Epoch 1: val_loss improved from 0.39714 to -624608256.00000, saving model to ./checkpoints/checkpoints_loss/weights.1717224224.hdf5\n",
      "1257/1257 [==============================] - 37s 26ms/step - loss: -625708032.0000 - accuracy: 0.0078 - val_loss: -624608256.0000 - val_accuracy: 0.0075 - lr: 2.0000e-04\n",
      "3636/3636 [==============================] - 12s 3ms/step - loss: -621974976.0000 - accuracy: 0.0072\n"
     ]
    }
   ],
   "source": [
    "_train_losses(model_default, x_train, y_train_int, (x_valid, y_valid_int))\n",
    "_train_losses(model_focal, x_train, y_train_int, (x_valid, y_valid_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{result_path}/result_losses_{_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, h in enumerate(history):\n",
    "    history_dict = {key: list(map(float, value)) for key, value in h.history.items()}\n",
    "    save_history(history_dict, f'history_losses_{i}_{_time}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"gold\", \"orange\", \"cyan\", \"magenta\", \"brown\", \"pink\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['loss'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.subplot(122)\n",
    "for idx, hist in enumerate(history):\n",
    "    plt.plot(hist.history['accuracy'], label=f'{results[\"Learning Rate\"][idx]}', color=colors[idx])\n",
    "    plt.title(f'Train Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim([0, EPOCHS])\n",
    "    plt.ylim([0.8, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{result_path}/result_losses_{_time}.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
